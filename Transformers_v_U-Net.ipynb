{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8OlrEDds6Xf"
      },
      "source": [
        "## Data Loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "URjymX51R2_r"
      },
      "outputs": [],
      "source": [
        "!pip install monai\n",
        "!pip install einops\n",
        "!pip install pynvml\n",
        "!pip install tensorboard-plugin-customizable-plots\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import einops\n",
        "import random\n",
        "\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from monai.losses import DiceLoss\n",
        "from monai.networks.nets import UNet, BasicUNet, FlexibleUNet\n",
        "from monai.networks.nets import SegResNet, UNETR, SwinUNETR\n",
        "from monai.metrics import compute_iou, compute_generalized_dice, CumulativeAverage\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter('runs/covid_segmentation')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "logger = logging.getLogger('CT_logger')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "file_log = logging.FileHandler('ct.log')\n",
        "file_log.setLevel(logging.DEBUG)\n",
        "logger.addHandler(file_log)\n",
        "logger.propagate = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QZky9R-yILTf"
      },
      "outputs": [],
      "source": [
        "def get_path_dict() -> list:\n",
        "  ''' creates a list of image addresses \n",
        "      return:\n",
        "        names_dict: dictionary, that contains\n",
        "                    a list of image paths for each set\n",
        "  '''\n",
        "  \n",
        "  names = os.listdir('/content/PNG_Covid/frames')\n",
        "  random.shuffle(names)\n",
        "  namelist = []\n",
        "  names_dict = {}\n",
        "  for name in names:\n",
        "    image = '/content/PNG_Covid/frames/' + name\n",
        "    mask = '/content/PNG_Covid/masks/' + name\n",
        "    namelist.append((image, mask))\n",
        "\n",
        "  # split into three subsets\n",
        "  set_len = len(namelist)\n",
        "  names_dict['Train'] = namelist[:int(set_len*0.6)]\n",
        "  names_dict['Val'] = namelist[int(set_len*0.6):int(set_len*0.8)]\n",
        "  names_dict['Test'] = namelist[int(set_len*0.8):]\n",
        "  \n",
        "  return names_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HwVnvrSSK4nH"
      },
      "outputs": [],
      "source": [
        "def get_set(namelist: list, augment=False) -> list:\n",
        "  ''' load and preproccess images \n",
        "      params:\n",
        "        namelist: list of imge paths\n",
        "        augment: wether to augment dataset\n",
        "      return:\n",
        "        loaded: list of loaded images\n",
        "  '''\n",
        "\n",
        "  loaded = []\n",
        "  for image, mask in namelist:\n",
        "    image, mask = get_images(image, mask)\n",
        "\n",
        "    if augment == True:\n",
        "      loaded += augment_set(image, mask)\n",
        "    else:\n",
        "      loaded.append((image, mask))\n",
        "\n",
        "  return loaded\n",
        "\n",
        "def get_images(image_path: str, mask_path: str) -> tuple:\n",
        "  ''' load image and mask '''\n",
        "\n",
        "  image, mask = read_image(image_path), read_image(mask_path)\n",
        "  image, mask = to_standart_format(image, mask)\n",
        "\n",
        "  return (image, mask)\n",
        "\n",
        "def to_standart_format(image: torch.tensor, mask: torch.tensor) -> tuple:\n",
        "  ''' transform to standart image format '''\n",
        "  \n",
        "  resize = torchvision.transforms.Resize(224)\n",
        "  image, mask = resize(image), resize(mask)\n",
        "  \n",
        "  image = image/255\n",
        "  mask = mask/255\n",
        "\n",
        "  return (image, mask)\n",
        "\n",
        "def augment_set(image: torch.tensor, mask: torch.tensor) -> list:\n",
        "  ''' augment dataset '''\n",
        "\n",
        "  new_loaded_list = []\n",
        "  augmentations = [transforms.RandomRotation(180), transforms.RandomAffine(180),\n",
        "                   transforms.RandomHorizontalFlip(p=1), transforms.RandomVerticalFlip(p=1)]\n",
        "  \n",
        "  new_loaded_list.append((image, mask))\n",
        "  combined = torch.cat((image.unsqueeze(0), mask.unsqueeze(0)), 0) # compbine to augment simultaneously\n",
        "\n",
        "  for augment in augmentations:\n",
        "    aug_image, aug_mask = augment(combined)\n",
        "    new_loaded_list.append((aug_image, aug_mask))\n",
        "\n",
        "  return new_loaded_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fIF0Tc3iLk_6"
      },
      "outputs": [],
      "source": [
        "class CTDataset(Dataset):\n",
        "  ''' create dataset of ct images \n",
        "      args:\n",
        "        path_dict: dictionary of sets and their list of paths\n",
        "        mode: a mode of evaluation\n",
        "        augment: wether to augment dataset\n",
        "  '''\n",
        "\n",
        "  def __init__(self, path_dict: dict, mode='Train', augment=False):\n",
        "    self.namelist = get_set(path_dict[mode], augment)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.namelist)\n",
        "  \n",
        "  def __getitem__(self, idx: int):\n",
        "    image, mask = self.namelist[idx]\n",
        "    return (image, mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaINJzUPbx4a"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y8jv0Io3kTev"
      },
      "outputs": [],
      "source": [
        "class ModelEvaluation:\n",
        "  ''' train and evaluate model\n",
        "      args:\n",
        "        model: model object\n",
        "        loade_dict: dictionary of loaders for each set\n",
        "  '''\n",
        "\n",
        "  def __init__(self, model: nn.Module, loader_dict: dict):\n",
        "    self.model = model\n",
        "    self.loader_dict = loader_dict\n",
        "\n",
        "    self.loss_fn = DiceLoss(sigmoid=True)\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "    self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
        "\n",
        "  \n",
        "  def train(self, epochs=1, batch_size=1):\n",
        "    self.model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    for epoch in range(epochs):\n",
        "      loss_cumul = CumulativeAverage()\n",
        "      iou_cumul = CumulativeAverage()\n",
        "      gd_cumul = CumulativeAverage()\n",
        "      recall_cumul = CumulativeAverage()\n",
        "      precision_cumul = CumulativeAverage()\n",
        "      f1_cumul = CumulativeAverage()\n",
        "      for batch, (ct, mask) in enumerate(self.loader_dict['train']):\n",
        "        ct = ct.to(device)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        model_out = self.model(ct)\n",
        "        loss = self.loss_fn(model_out, mask)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "      \n",
        "        model_out = nn.Sigmoid()(model_out)\n",
        "        gd, iou, recall, precision, f1 = self.compute_metrics(model_out, mask)\n",
        "        loss_cumul.append(loss)\n",
        "        iou_cumul.append(iou)\n",
        "        gd_cumul.append(gd)\n",
        "        recall_cumul.append(recall)\n",
        "        precision_cumul.append(precision)\n",
        "        f1_cumul.append(f1)\n",
        "\n",
        "      loss_avg = loss_cumul.aggregate()\n",
        "      iou_avg = iou_cumul.aggregate()\n",
        "      gd_avg = gd_cumul.aggregate()\n",
        "      recall_avg = recall_cumul.aggregate()\n",
        "      precision_avg = precision_cumul.aggregate()\n",
        "      f1_avg = f1_cumul.aggregate()\n",
        "\n",
        "      writer.add_scalar('Loss_AVG/train', loss_avg, epoch)\n",
        "      writer.add_scalar('IOU_AVG/train', iou_avg, epoch)\n",
        "      writer.add_scalar('GD_AVG/train', gd_avg, epoch)\n",
        "      writer.add_scalar('Recall_AVG/train', recall_avg, epoch)\n",
        "      writer.add_scalar('Precision_AVG/train', precision_avg, epoch)\n",
        "      writer.add_scalar('F1_AVG/train', f1_avg, epoch)\n",
        "      logger.debug(f'DEBUG| location: ModelEvalutation.train | loss_avg: {loss_avg}, iou_avg: {iou_avg}')\n",
        "      self.scheduler.step(loss)\n",
        "\n",
        "    writer.flush()\n",
        "  \n",
        "\n",
        "  def evaluate(self, mode='val', batch_size=1):\n",
        "    self.model.eval()\n",
        "    loss_cumul = CumulativeAverage()\n",
        "    iou_cumul = CumulativeAverage()\n",
        "    gd_cumul = CumulativeAverage()\n",
        "    recall_cumul = CumulativeAverage()\n",
        "    precision_cumul = CumulativeAverage()\n",
        "    f1_cumul = CumulativeAverage()\n",
        "    with torch.no_grad():\n",
        "      for batch, (ct, mask) in enumerate(self.loader_dict[mode]):\n",
        "        ct = ct.to(device)\n",
        "        mask = mask.to(device)\n",
        "        model_out = self.model(ct)\n",
        "        loss = self.loss_fn(model_out, mask)\n",
        "        \n",
        "        model_out = nn.Sigmoid()(model_out)\n",
        "        gd, iou, recall, precision, f1 = self.compute_metrics(model_out, mask)\n",
        "        loss_cumul.append(loss, count=batch_size)\n",
        "\n",
        "        iou_cumul.append(iou)\n",
        "        gd_cumul.append(gd)\n",
        "        recall_cumul.append(recall)\n",
        "        precision_cumul.append(precision)\n",
        "        f1_cumul.append(f1)\n",
        "\n",
        "        if batch % 50 == 0: \n",
        "           writer.add_images(f'model_out/{mode}', (model_out > 0.5), global_step=batch)\n",
        "           writer.add_images(f'mask/{mode}', mask, global_step=batch)\n",
        "    \n",
        "    loss_avg = loss_cumul.aggregate()\n",
        "    iou_avg = iou_cumul.aggregate()\n",
        "    gd_avg = gd_cumul.aggregate()\n",
        "    recall_avg = recall_cumul.aggregate()\n",
        "    precision_avg = precision_cumul.aggregate()\n",
        "    f1_avg = f1_cumul.aggregate()\n",
        "            \n",
        "    print(f'loss_avg: {loss_avg}, iou_avg: {iou_avg}, gd_avg: {gd_avg}')\n",
        "    print(f'recall_avg: {recall_avg}, precision_avg: {precision_avg}, f1_avg: {f1_avg}')\n",
        "\n",
        "    writer.flush()\n",
        "  \n",
        "  def to_monai_form(self, y_pred: torch.tensor, y: torch.tensor) -> tuple:\n",
        "    ''' transform to monai-compatible form '''\n",
        "    y_pred = y_pred > 0.5\n",
        "    y = y > 0.5\n",
        "    return (y_pred, y)\n",
        "\n",
        "  def compute_metrics(self, y_pred: torch.tensor, y: torch.tensor) -> list:\n",
        "    ''' compute Monai metrics '''\n",
        "\n",
        "    y_pred, y = self.to_monai_form(y_pred, y)\n",
        "    GD = compute_generalized_dice(y_pred, y).mean()\n",
        "    IOU = compute_iou(y_pred, y, ignore_empty=False).mean()\n",
        "\n",
        "    recall, precision, f1 = self.additional_metrics(y_pred, y)\n",
        "    \n",
        "    metrics = [float(GD), float(IOU), float(recall),\n",
        "               float(precision), float(f1)]\n",
        "\n",
        "    return metrics\n",
        "  \n",
        "  def additional_metrics(self, y_pred: torch.tensor, y: torch.tensor) -> tuple:\n",
        "    ''' compute additional metrics '''\n",
        "\n",
        "    inter = (y_pred * y).sum(dim=[1,2,3])\n",
        "    \n",
        "    recall = (inter + 1)/(y.sum(dim=[1,2,3]) + 1)\n",
        "    precision = (inter + 1)/(y_pred.sum(dim=[1,2,3]) + 1)\n",
        "    f1 = 2*((precision*recall)/(precision+recall))\n",
        "\n",
        "    return recall.mean(), precision.mean(), f1.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMPS1zlV_2-9"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e1ULBJs-AAz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0404d9fa-74eb-4d46-d2df-b713d569f77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BasicUNet features: (32, 32, 64, 128, 256, 32).\n"
          ]
        }
      ],
      "source": [
        "swin = SwinUNETR(in_channels=3, out_channels=3, img_size=(224,224), drop_rate=0.5, spatial_dims=2, use_checkpoint=True).to(device)\n",
        "unet = UNet(spatial_dims=2, in_channels=3, out_channels=3, channels=(4, 8, 16), strides=(2, 2)).to(device)\n",
        "basic = BasicUNet(spatial_dims=2, in_channels=3, out_channels=3, dropout=0.5).to(device)\n",
        "unetr = UNETR(in_channels=3, out_channels=3, img_size=(224, 224), dropout_rate=0.5, spatial_dims=2).to(device)\n",
        "segresnet = SegResNet(in_channels=3, out_channels=3, dropout_prob=0.5, spatial_dims=2).to(device)\n",
        "flexible = FlexibleUNet(in_channels=3, out_channels=3, backbone='efficientnet-b0', spatial_dims=2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = swin # pick what model to use"
      ],
      "metadata": {
        "id": "qLEwK7wNvNVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF0cIj7K_64Z",
        "outputId": "9f384f54-5269-4180-dae7-0deb7c276477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "path_dict = get_path_dict()\n",
        "\n",
        "trainset = CTDataset(path_dict, 'Train', True)\n",
        "valset = CTDataset(path_dict, 'Val')\n",
        "testset = CTDataset(path_dict, 'Test')\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 4\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "valloader = DataLoader(valset, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "testloader = DataLoader(testset, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "loader_dict = {'train': trainloader, 'val': valloader, 'test': testloader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBT5-tL9EweB"
      },
      "outputs": [],
      "source": [
        "evaluate = ModelEvaluation(model, loader_dict)\n",
        "evaluate.train(epochs=30, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0S996kNdJBC",
        "outputId": "113e3e1a-26c0-4003-96d3-4641ec216e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_avg: 0.22081801295280457, iou_avg: 0.6617366075515747, gd_avg: 0.7819307446479797\n",
            "recall_avg: 0.8226538896560669, precision_avg: 0.7754347920417786, f1_avg: 0.7826881408691406\n"
          ]
        }
      ],
      "source": [
        "evaluate.evaluate('train', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abeXd7dUvhdZ",
        "outputId": "d5c2f2e0-bde2-4195-9cb4-fc5986cfa86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_avg: 0.24651551246643066, iou_avg: 0.6342942714691162, gd_avg: 0.7557283043861389\n",
            "recall_avg: 0.7921702265739441, precision_avg: 0.7616923451423645, f1_avg: 0.7569184899330139\n"
          ]
        }
      ],
      "source": [
        "evaluate.evaluate('val', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhtDdWq7c7rD",
        "outputId": "03afe27f-dba5-47a3-b1af-a08e48a719d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_avg: 0.24115262925624847, iou_avg: 0.640584409236908, gd_avg: 0.7609906196594238\n",
            "recall_avg: 0.7951751351356506, precision_avg: 0.7647630572319031, f1_avg: 0.7618975043296814\n"
          ]
        }
      ],
      "source": [
        "evaluate.evaluate('test', batch_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "B8OlrEDds6Xf",
        "eaINJzUPbx4a"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}