{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B8OlrEDds6Xf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and preprocessing"
      ],
      "metadata": {
        "id": "B8OlrEDds6Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install SimpleITK\n",
        "# !pip install torchio\n",
        "# !pip install monai\n",
        "# !pip install einops\n",
        "# !pip install tensorboard-plugin-3d\n",
        "# !pip install pynvml\n",
        "\n",
        "# !unzip /content/drive/MyDrive/COVID-19-20_v2.zip\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchio as tio\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import functools\n",
        "import logging\n",
        "import einops\n",
        "\n",
        "from torch import nn\n",
        "from monai.networks.nets import VNet, UNETR, SwinUNETR\n",
        "from monai.metrics import compute_generalized_dice, compute_average_surface_distance\n",
        "from monai.metrics import compute_surface_dice, compute_roc_auc, compute_iou\n",
        "from monai.metrics import compute_hausdorff_distance, CumulativeAverage\n",
        "from monai.visualize.img2tensorboard import plot_2d_or_3d_image\n",
        "from monai.losses import GeneralizedDiceLoss, DiceLoss, DiceCELoss\n",
        "from functools import cached_property\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter('runs/covid_segmentation')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "logger = logging.getLogger('CT_logger')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "file_log = logging.FileHandler('ct.log')\n",
        "file_log.setLevel(logging.DEBUG)\n",
        "logger.addHandler(file_log)\n",
        "logger.propagate = False"
      ],
      "metadata": {
        "id": "URjymX51R2_r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xlsx = pd.ExcelFile('/content/COVID-19-20_TrainValidation.xlsx')\n",
        "df_train = pd.read_excel(xlsx, 'Train set')\n",
        "df_test = pd.read_excel(xlsx, 'Validation set')\n",
        "\n",
        "val_split = int(len(df_train)*0.8)\n",
        "\n",
        "train_namelist = list(df_train['FILENAME'])[:val_split]\n",
        "val_namelist = list(df_train['FILENAME'])[val_split:]\n",
        "test_namelist = list(df_test['FILENAME'])"
      ],
      "metadata": {
        "id": "wDx4thT7C3iv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CT:\n",
        "  def __init__(self, CT_ID, folder_path):\n",
        "    self.CT_ID = CT_ID\n",
        "    self.folder_path = folder_path\n",
        "  \n",
        "  @cached_property\n",
        "  def volume(self):\n",
        "    try: #change that\n",
        "      ct = sitk.ReadImage(self.folder_path + self.CT_ID + '.nii')\n",
        "    except Exception:\n",
        "      ct = sitk.ReadImage(self.folder_path + self.CT_ID + '_ct.nii')\n",
        "    mask = sitk.ReadImage(self.folder_path + self.CT_ID + '_seg.nii')\n",
        "\n",
        "    ct_np = sitk.GetArrayFromImage(ct)\n",
        "    mask_np = sitk.GetArrayFromImage(mask)\n",
        "\n",
        "    ct_np = self.preprocessing(ct_np)\n",
        "    mask_np = self.preprocessing(mask_np)\n",
        "\n",
        "    return (ct_np, mask_np)\n",
        "  \n",
        "  def preprocessing(self, image):\n",
        "    image = np.clip(image, -1000, 1000)\n",
        "    image = image[:32] # change that\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "RtHjSAKdCrbc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(ct, mask, aug_type): # think if it should stay a stand alone function\n",
        "  aug_dict = {'flip': tio.RandomFlip(), \n",
        "              'ED': tio.RandomElasticDeformation(),\n",
        "              'affine': tio.RandomAffine(),\n",
        "              'anistropy': tio.RandomAnisotropy(),\n",
        "              'noise': tio.RandomNoise(),\n",
        "              'blur': tio.RandomBlur(), \n",
        "              'swap': tio.RandomSwap()}\n",
        "  \n",
        "  combined = torch.cat((ct.unsqueeze(0), mask.unsqueeze(0)), 0)\n",
        "\n",
        "  ct, mask = aug_dict[aug_type](combined)\n",
        "\n",
        "  return ct, mask"
      ],
      "metadata": {
        "id": "ZgFo-4nISgrV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CTDataset(Dataset):\n",
        "  def __init__(self, namelist, folder_path, augmentation_list=[]):\n",
        "    self.folder_path = folder_path\n",
        "    namelist_l = len(namelist) # change variable names\n",
        "    self.namelist = zip(namelist, [None]*namelist_l)\n",
        "    self.namelist = list(self.namelist)\n",
        "    \n",
        "    if augmentation_list:\n",
        "      for aug_type in augmentation_list:\n",
        "        self.namelist += list(zip(namelist, [aug_type]*namelist_l))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.namelist)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    ct_id, aug_type = self.namelist[idx]\n",
        "    ct, mask = CT(ct_id, self.folder_path).volume\n",
        "    ct, mask = torch.from_numpy(ct), torch.from_numpy(mask)\n",
        "\n",
        "    if aug_type:\n",
        "      ct, mask = augment(ct, mask, aug_type)\n",
        "\n",
        "    return ct, mask"
      ],
      "metadata": {
        "id": "moe_zO__Y2Fc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "eaINJzUPbx4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelEvaluation:\n",
        "  def __init__(self, model, loader_dict):\n",
        "    self.model = model\n",
        "    self.loader_dict = loader_dict\n",
        "\n",
        "    self.loss_fn = GeneralizedDiceLoss()\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=0.001)\n",
        "  \n",
        "  def to_monai_shape(self, y_pred, y):\n",
        "    y_pred = y_pred.permute(0,1,3,4,2)\n",
        "    y = y.permute(0,1,3,4,2)\n",
        "    return (y_pred, y)\n",
        "  \n",
        "  def train(self, epochs=1, batch_size=1):\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    run_avg = CumulativeAverage()\n",
        "\n",
        "    self.model.train()\n",
        "    for epoch in range(epochs):\n",
        "      for batch, (ct, mask) in enumerate(self.loader_dict['train']):\n",
        "        ct = ct.unsqueeze(1).to(device, dtype=torch.float32)\n",
        "        mask = mask.unsqueeze(1).to(device, dtype=torch.float32)\n",
        "        model_out = self.model(ct)\n",
        "\n",
        "        ct = ct.detach().cpu()\n",
        "\n",
        "        model_out, mask = self.to_monai_shape(model_out, mask)\n",
        "        loss = self.loss_fn(model_out, mask)\n",
        "        \n",
        "        mask = mask.detach().cpu()\n",
        "        model_out = model_out.detach().cpu()\n",
        "\n",
        "        run_avg.append(loss, count=batch_size)\n",
        "\n",
        "        if batch == 0: # temporary\n",
        "          logger.debug(f'DEBUG| location: ModelEvalutation.train | min: \\\n",
        "           {float(torch.min(model_out))}, max: {float(torch.max(model_out))}')\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "          metrics = Metrics(model_out > 0.5, mask).compute()\n",
        "          writer.add_scalar('Loss/train', loss, batch)\n",
        "          writer.add_scalar('Precision/train', metrics['precision'], batch)\n",
        "          writer.add_scalar('Recall/train', metrics['recall'], batch)\n",
        "          writer.add_scalar('IOU/train', metrics['IOU'], batch)\n",
        "          plot_2d_or_3d_image((model_out > 0.5), step=batch, writer=writer, tag='model_out') # !\n",
        "          plot_2d_or_3d_image(mask, step=batch, writer=writer, tag='mask')\n",
        "          logger.debug(f'DEBUG| location: ModelEvalutation.train | epoch: {epoch}, batch: {batch}, loss: {loss.item()}')\n",
        "          logger.debug(f'DEBUG| location: ModelEvalutation.train | {str(metrics)}')\n",
        "          \n",
        "          \n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "      \n",
        "\n",
        "    avg_loss = run_avg.aggregate()\n",
        "    logger.debug(f'DEBUG| location: ModelEvalutation.train | avg_loss: {avg_loss}')\n",
        "\n",
        "    writer.add_graph(self.model, ct)\n",
        "    writer.flush()\n",
        "  \n",
        "  def evaluate(self, mode='val', batch_size=1):\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    run_avg = CumulativeAverage()\n",
        "\n",
        "    self.model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch, (ct, mask) in enumerate(self.loader_dict[mode]):\n",
        "        ct = ct.unsqueeze(1).to(device, dtype=torch.float32)\n",
        "        mask = mask.unsqueeze(1).to(device, dtype=torch.float32)\n",
        "        model_out = self.model(ct)\n",
        "        loss = self.loss_fn(model_out, mask)\n",
        "        run_avg.append(loss, count=batch_size)\n",
        "\n",
        "        if batch % 10 == 0: \n",
        "          metrics = Metrics(model_out, mask).compute()\n",
        "          writer.add_scalar(f'Loss/{mode}', loss, batch)\n",
        "          writer.add_scalar(f'F1/{mode}', metrics['F1'], batch)\n",
        "          plot_2d_or_3d_image((model_out > 0.5), step=batch, writer=writer, tag='model_out')\n",
        "          plot_2d_or_3d_image(mask, step=batch, writer=writer, tag='mask')\n",
        "    \n",
        "    avg_loss = run_avg.aggregate()\n",
        "    print('avg_loss:', avg_loss)\n",
        "\n",
        "    writer.flush()"
      ],
      "metadata": {
        "id": "Y8jv0Io3kTev"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics:\n",
        "  def __init__(self, y_pred, y):\n",
        "    self.y = y\n",
        "    self.y_pred = y_pred\n",
        "  \n",
        "  def compute(self):\n",
        "    st = self.standart_metrics()\n",
        "    seg = self.segmentation_metrics()\n",
        "    st.update(seg)\n",
        "\n",
        "    return st\n",
        "  \n",
        "  def standart_metrics(self): # think about correctness of this\n",
        "    tp = (self.y_pred * self.y).sum(dim=[1,2,3,4])\n",
        "    \n",
        "    precision = tp/self.y_pred.sum(dim=[1,2,3,4])\n",
        "    recall = tp/self.y.sum(dim=[1,2,3,4])\n",
        "    f1 = (2*precision*recall)/(precision+recall)\n",
        "\n",
        "    return {'precision': float(precision), 'recall': float(recall), 'F1': float(f1)}\n",
        "\n",
        "\n",
        "  def segmentation_metrics(self):\n",
        "    y_pred = self.y_pred > 0.6\n",
        "\n",
        "    PA = self.pixelwise_accuracy()\n",
        "    GDL = compute_generalized_dice(y_pred, self.y, False)\n",
        "    ASD = compute_average_surface_distance(y_pred, self.y)\n",
        "    IOU = compute_iou(y_pred, self.y)\n",
        "    Hausdorff = compute_hausdorff_distance(y_pred, self.y)\n",
        "\n",
        "    return {'PA': float(PA), 'GDL': float(GDL), 'ASD': float(ASD),\n",
        "            'IOU': float(IOU), 'Hausdorff': float(Hausdorff)}\n",
        "\n",
        "  \n",
        "  def pixelwise_accuracy(self):\n",
        "    inter = (self.y_pred * self.y).sum(dim=[1,2,3,4])\n",
        "    union = self.y_pred.sum(dim=[1,2,3,4]) + self.y.sum(dim=[1,2,3,4])\n",
        "    PA = (inter + 1)/(self.y.sum(dim=[1,2,3,4]) + 1)\n",
        "\n",
        "    return PA.mean()"
      ],
      "metadata": {
        "id": "2EdGQbteFMTW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "OMPS1zlV_2-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VNet(in_channels=1, out_channels=1)\n",
        "model.out_tr.conv2 = nn.Sequential(nn.Conv3d(1, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1)),\n",
        "                                   nn.Sigmoid())\n",
        "model = model.to(device, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "e1ULBJs-AAz0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = CTDataset(train_namelist, '/content/Train/', augmentation_list=['flip', 'blur', 'noise', 'swap'])\n",
        "\n",
        "valset = CTDataset(val_namelist, '/content/Train/')\n",
        "testset = CTDataset(test_namelist, '/content/Validation/')\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)\n",
        "\n",
        "loader_dict = {'train': trainloader, 'val': valloader, 'test': testloader}"
      ],
      "metadata": {
        "id": "pF0cIj7K_64Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate = ModelEvaluation(model, loader_dict)"
      ],
      "metadata": {
        "id": "SBT5-tL9EweB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "evaluate.train(batch_size=batch_size)"
      ],
      "metadata": {
        "id": "yXVEX3cYE3Bk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "07ae0fed-58b7-409e-a84f-5e6d58dcd900"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/monai/metrics/surface_distance.py:161: UserWarning: the ground truth of class 0 is all 0, this may result in nan/inf distance.\n",
            "  warnings.warn(f\"the ground truth of class {c} is all 0, this may result in nan/inf distance.\")\n",
            "/usr/local/lib/python3.9/dist-packages/monai/metrics/hausdorff_distance.py:168: UserWarning: the ground truth of class 0 is all 0, this may result in nan/inf distance.\n",
            "  warnings.warn(f\"the ground truth of class {c} is all 0, this may result in nan/inf distance.\")\n",
            "/usr/local/lib/python3.9/dist-packages/monai/metrics/utils.py:219: UserWarning: y should be a binarized tensor.\n",
            "  warnings.warn(f\"{name} should be a binarized tensor.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-dc73069f4c71>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-5416e5c26a50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ground truth 0 issue\n",
        "# y should be a binarized tensor"
      ],
      "metadata": {
        "id": "yTOHhBEo0TBK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}